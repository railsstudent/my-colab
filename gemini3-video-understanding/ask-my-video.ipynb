{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ee6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install matplotlib\n",
    "%pip install os\n",
    "%pip install dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialAnalysis(BaseModel):\n",
    "    percentage: int = Field(description=\"Integer similarity score.\")\n",
    "    similarities: list[str] = Field(description=\"Key similarities.\")\n",
    "    differences: list[str] = Field(description=\"Key differences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8761749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genai_client():\n",
    "    import os\n",
    "\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found in .env file\")    \n",
    "\n",
    "    # Configure the client with your API key\n",
    "    client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_vertexai_client():\n",
    "    import os\n",
    "    \n",
    "    cloud_api_key = os.getenv(\"GOOGLE_CLOUD_API_KEY\")\n",
    "    if not cloud_api_key:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_API_KEY not found in .env file\")\n",
    "    \n",
    "    # Configure the client with your API key\n",
    "    client = genai.Client(\n",
    "        vertexai=True, \n",
    "        api_key=cloud_api_key, \n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path: str):\n",
    "    try:\n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{image_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e88721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inline_data_part(image_path: str):\n",
    "    import mimetypes\n",
    "\n",
    "    try:\n",
    "        mime_type, _ = mimetypes.guess_type(image_path)\n",
    "        if mime_type is None:\n",
    "            mime_type = 'application/octet-stream'\n",
    "            print(f\"Warning: Could not determine MIME type for {image_path}. Defaulting to {mime_type}.\")\n",
    "\n",
    "        file_bytes: bytes | None = None\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            file_bytes = image_file.read()\n",
    "        \n",
    "        if file_bytes is None:\n",
    "            raise Exception(f\"Unable to read the bytes from {image_path}\")\n",
    "    \n",
    "        return types.Part(\n",
    "            inline_data=types.Blob(\n",
    "                mime_type=mime_type,\n",
    "                data=file_bytes\n",
    "            ),\n",
    "            media_resolution={\"level\": \"media_resolution_high\"}\n",
    "        ) \n",
    "    except FileNotFoundError:\n",
    "        print (f\"Error: The file was not found at {image_path}\")\n",
    "    except Exception as e:\n",
    "        print (f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Configure the client with your API key\n",
    "# client = create_genai_client()\n",
    "client = create_vertexai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3440c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_facial_images(person_a_image: str, person_b_image: str):\n",
    "    def clean_json_string(raw_string):\n",
    "        # Remove the markdown code blocks\n",
    "        clean_str = raw_string.strip()\n",
    "        if clean_str.startswith(\"```json\"):\n",
    "            clean_str = clean_str[7:]\n",
    "        if clean_str.endswith(\"```\"):\n",
    "            clean_str = clean_str[:-3]\n",
    "        return clean_str.strip()\n",
    "\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Role: You are an Expert Biometric Analyst and Facial Recognition Specialist. Your expertise lies in anthropometric comparison, analyzing facial landmarks, bone structure, and morphological traits.\n",
    "\n",
    "    Task: Analyze the attached image(s). Compare the physical appearance of the two individuals shown. If two separate images are provided, treat the first as Person A and the second as Person B. If one image containing two people is provided, treat the person on the left as Person A and the person on the right as Person B.\n",
    "\n",
    "    Analysis Criteria:\n",
    "    Focus strictly on biological and physical traits (facial geometry, feature shapes, and proportions). Ignore clothing, lighting, camera angles, or accessories (glasses, hats) unless they obscure features.\n",
    "\n",
    "    The Rule of Similarity (Visual Scoring Rubric):\n",
    "    You must assign a final similarity percentage based strictly on this scale:\n",
    "\n",
    "    0% - 10% (Dissimilar): Polar opposites. No shared facial geometry or features; different phenotypes.\n",
    "    11% - 20% (Faint Connection): Very weak link; perhaps a shared broad head shape, but all specific features differ.\n",
    "    21% - 30% (Vague Resemblance): Superficial similarities only (e.g., similar eye color or hair texture only), but the faces look unrelated.\n",
    "    31% - 40% (Partial Overlap): Noticeable but minor similarities. Maybe the nose or mouth is similar, but the overall bone structure is different.\n",
    "    41% - 50% (Moderate Association): Reminiscent. One major anatomical zone aligns (e.g., eyes/brows), but the rest of the face is distinct.\n",
    "    51% - 60% (Balanced Similarity): Comparable. Distinct individuals, but there is enough overlap in bone structure to suggest a relation.\n",
    "    61% - 70% (Strong Resemblance): \"Cousin\" status. Strong resemblance in the \"map\" of the face; differences are only in the details/nuance.\n",
    "    71% - 80% (Kindred Spirits): High resemblance. They share facial ratios that suggest a blood relation (e.g., parent/child or first cousins), but are clearly distinguishable as different people.\n",
    "    81% - 90% (Biological Sibling / Doppelg√§nger): Extremely high correlation. This tier represents biological sisters/brothers who look very similar, or unrelated high-grade lookalikes. They share almost all facial features, with only minor structural variances.\n",
    "    91% - 100% (Identical Match): The same person or identical twins. Facial geometry and bone structure are exact matches. Any visible differences are strictly superficial (e.g., age, styling, or weight) and not structural.\n",
    "\n",
    "    Output Format:\n",
    "    Please provide the result strictly in the following format:\n",
    "\n",
    "    Similarity Score: [Insert Integer]%\n",
    "\n",
    "    Key Similarities:\n",
    "    - [Detail 1]\n",
    "    - [Detail 2]\n",
    "    - [Detail 3]\n",
    "\n",
    "    Key Differences:\n",
    "    - [Detail 1]\n",
    "    - [Detail 2]\n",
    "    - [Detail 3]\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=prompt),\n",
    "                    get_inline_data_part(person_a_image),\n",
    "                    get_inline_data_part(person_b_image),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=FacialAnalysis.model_json_schema(),\n",
    "            tools=[types.Tool(\n",
    "                google_search=types.GoogleSearch()\n",
    "            )],\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_HIGH,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "    #     for part in response.candidates[0].content.parts:            \n",
    "    #         if part.thought:\n",
    "    #             print(\"Thought summary:\", part.text)\n",
    "    #         elif part.text:\n",
    "    #             print(\"Text: \", part.text)\n",
    "\n",
    "    result = FacialAnalysis.model_validate_json(clean_json_string(response.text))\n",
    "    return result\n",
    "\n",
    "def print_result(person_a_image: str, person_b_image: str):\n",
    "    result = analyse_facial_images(person_a_image=person_a_image, person_b_image=person_b_image)\n",
    "\n",
    "    load_image(person_a_image)\n",
    "    load_image(person_b_image)\n",
    "    print(\"Percentage: \", result.percentage)\n",
    "    print (\"Similarities:\")\n",
    "    for s in result.similarities:\n",
    "        print(\"- \", s)\n",
    "\n",
    "    print (\"Differences:\")\n",
    "    for d in result.differences:\n",
    "        print(\"-\",  d)\n",
    "    print(\"========================================================================\")\n",
    "\n",
    "def print_test_cases(heading: str, cases: list[list[str]]):\n",
    "    print(heading)\n",
    "    for case in cases:\n",
    "        print_result(person_a_image=case[0], person_b_image=case[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilar_cases = [\n",
    "    ['./images/patrick.jpg', './images/logan_kilpatrick.jpg'],\n",
    "    ['./images/Natalie_Portman.jpg', './images/Little_S.jpg'],\n",
    "    ['./images/park_bo_gum.jpg', './images/Little_S.jpg'],\n",
    "]\n",
    "\n",
    "print_test_cases(heading=\"Dissimilar cases\", cases=dissimilar_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_cases = [\n",
    "    ['./images/Big_S.jpg', './images/Little_S.jpg'],\n",
    "    ['./images/Natalie_Portman.jpg', './images/Keira_Knightley.jpg'],\n",
    "]\n",
    "\n",
    "print_test_cases(heading=\"Similar cases\", cases=similar_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "identical_cases = [\n",
    "    ['./images/Ashley_Olsen.jpg', './images/Mary_Kate_Olsen.jpg'],\n",
    "    # ['./images/Cole_Sprouse.jpg', './images/Dylan_Sprouse.jpg'],\n",
    "    ['./images/patrick.jpg', './images/patrick.jpg']\n",
    "]\n",
    "\n",
    "print_test_cases(heading=\"Identical twin cases\", cases=identical_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
