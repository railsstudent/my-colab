{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ee6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install os\n",
    "%pip install dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segment(BaseModel):\n",
    "    start: str = Field(description=\"Start of a segment.\")\n",
    "    end: str = Field(description=\"End of a segment.\")\n",
    "    reason: str | None = Field(None, description=\"Reason why this segment is important.\")\n",
    "\n",
    "class GroundedVideoAnswer(BaseModel):\n",
    "    answer: str = Field(..., description=\"answer\")\n",
    "    segments: list[Segment] = Field(..., description=\"a list of video segments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8761749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vertexai_client():\n",
    "    import os\n",
    "    \n",
    "    cloud_api_key = os.getenv(\"GOOGLE_CLOUD_API_KEY\")\n",
    "    if not cloud_api_key:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_API_KEY not found in .env file\")\n",
    "    \n",
    "    # Configure the client with your API key\n",
    "    client = genai.Client(\n",
    "        vertexai=True, \n",
    "        api_key=cloud_api_key, \n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Configure the client with your API key\n",
    "client = create_vertexai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_string(raw_string):\n",
    "    # Remove the markdown code blocks\n",
    "    clean_str = raw_string.strip()\n",
    "    if clean_str.startswith(\"```json\"):\n",
    "        clean_str = clean_str[7:]\n",
    "    if clean_str.endswith(\"```\"):\n",
    "        clean_str = clean_str[:-3]\n",
    "    return clean_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3440c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_my_youtube(file_uri: str, question: str, video_metadata: types.VideoMetadata | None) -> GroundedVideoAnswer:\n",
    "   \n",
    "    video_metadata_dict = video_metadata.__dict__ if video_metadata is not None else {}\n",
    "    # custom frame rate and clipping interval. \n",
    "    # decrease frame rate when 0 < fps < 1\n",
    "    merged_dict = {**video_metadata_dict, \"fps\": 0.5}\n",
    "    merged_video_dict = types.VideoMetadata(**merged_dict)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-3-flash-preview',\n",
    "        contents=types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(\n",
    "                    file_data=types.FileData(file_uri=file_uri, mime_type=\"video/mp4\"),\n",
    "                    video_metadata=merged_video_dict  \n",
    "                ),\n",
    "                types.Part(text=question)\n",
    "            ]\n",
    "        ),\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=GroundedVideoAnswer.model_json_schema(),\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_LOW,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result = GroundedVideoAnswer.model_validate_json(clean_json_string(response.text))\n",
    "    return result\n",
    "\n",
    "def print_result(file_uri: str, question: str, video_metadata: types.VideoMetadata | None = None):\n",
    "    result = ask_my_youtube(file_uri=file_uri, \n",
    "        question=question, \n",
    "        video_metadata=video_metadata\n",
    "    )\n",
    "\n",
    "    print(\"Question: \", question)\n",
    "    print(\"Answer: \", result.answer)\n",
    "    print (\"Segments:\")\n",
    "    for s in result.segments:\n",
    "        print(\"- \", f\"[{s.start} - {s.end}], reason: {s.reason}\")\n",
    "\n",
    "    return result.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short videos (~14 minutes) about Nano Banana generation\n",
    "# file_uri = \"https://youtu.be/v6B44n1V9no?si=lupM2r3kDGxFzzHr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95992d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_result(file_uri=file_uri, question=\"Summarize the video in three sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_result(file_uri=file_uri, question=\"Explain her demo that generates multiple images using Nano Banana Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d63fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_result(file_uri=file_uri, question=\"How did she build the prompt at each step?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A long YouTube video (26:53) about gemini 2.5 flash tts mode\n",
    "file_uri = \"https://youtu.be/R9LZrysSil0?si=pSXGE1fKCPVKLdWc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class QuestionType(Enum):\n",
    "    Technical=\"Technical\"\n",
    "    Visual=\"Visual\"\n",
    "    Concept=\"Concept\"\n",
    "\n",
    "class FollowUpQuestion(BaseModel):\n",
    "    id: int\n",
    "    type: QuestionType\n",
    "    text: str\n",
    "    reason: str\n",
    "\n",
    "class FollowUpQuestions(BaseModel):\n",
    "    follow_up_analysis: str\n",
    "    questions: list[FollowUpQuestion]\n",
    "\n",
    "def get_followup_questions(file_uri: str, previous_answer: str, video_metadata: types.VideoMetadata | None = None) -> FollowUpQuestions:\n",
    "    system_prompt = \"\"\"\n",
    "### ROLE\n",
    "You are the \"Expert Insight Architect,\" a specialist in Socratic inquiry and multimodal analysis. Your expertise lies in identifying \"logical gaps\" and \"hidden nuances\" within video content to help users explore a topic beyond the surface-level answer.\n",
    "\n",
    "### OBJECTIVE\n",
    "Based on a provided YouTube video and a previous answer, generate three (3) highly targeted follow-up questions. These questions should encourage the user to think deeper about the visual, technical, or conceptual evidence presented in the video.\n",
    "\n",
    "### OPERATING PRINCIPLES\n",
    "1. MULTIMODAL GROUNDING: Every question must be directly related to something seen or heard in the provided video. Do not ask generic questions that could apply to any video on the topic.\n",
    "2. THE \"THINKING\" PHASE: Use your internal reasoning (Thinking Mode) to cross-reference the previous answer against the video's full timeline. Identify what was missed, glossed over, or requires further proof.\n",
    "3. DIVERSITY OF INQUIRY: Provide three distinct types of questions:\n",
    "   - THE TECHNICAL DRILL-DOWN: Focus on a specific detail, data point, or instruction mentioned.\n",
    "   - THE VISUAL CONTEXT: Focus on something shown on screen (charts, demos, body language, or environment).\n",
    "   - THE CONCEPTUAL EXTENSION: Link a point made in the video to a broader implication or real-world application.\n",
    "\n",
    "### OUTPUT FORMAT\n",
    "You must return the response as a structured JSON object for seamless UI integration.\n",
    "{\n",
    "  \"follow_up_analysis\": \"A brief internal thought on why these questions were chosen.\",\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"type\": \"Technical\",\n",
    "      \"question\": \"string\",\n",
    "      \"reason\": \"A small clue about where in the video this is addressed.\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"type\": \"Visual\",\n",
    "      \"question\": \"string\",\n",
    "      \"reason\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"type\": \"Conceptual\",\n",
    "      \"question\": \"string\",\n",
    "      \"reason\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "### CRITICAL CONSTRAINT\n",
    "Never suggest a question that has already been fully answered by the provided \"Previous Answer\" text. Always push for \"Next-Level\" understanding.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-3-flash-preview',\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"model\",\n",
    "                parts=[types.Part(text=system_prompt)]\n",
    "            ),\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(\n",
    "                        file_data=types.FileData(file_uri=file_uri, mime_type=\"video/mp4\"),\n",
    "                        video_metadata=video_metadata\n",
    "                    ),\n",
    "                    types.Part(text=f\"Previous answer: {previous_answer}\")\n",
    "                ]\n",
    "        )],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=FollowUpQuestions.model_json_schema(),\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_LOW,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    result = FollowUpQuestions.model_validate_json(clean_json_string(response.text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a745a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_offset =  f\"{22 * 60 + 49}s\"\n",
    "end_offset = f\"{26 * 60 + 40}s\"\n",
    "\n",
    "video_metadata = types.VideoMetadata(start_offset=start_offset, end_offset=end_offset)\n",
    "previous_answer = print_result(\n",
    "    file_uri=file_uri, \n",
    "    question=\"What was Connie saying in this video clip? Provide the top 3 most relevant segments.\",\n",
    "    video_metadata=video_metadata\n",
    ")\n",
    "\n",
    "followup_questions = get_followup_questions(\n",
    "    file_uri=file_uri, \n",
    "    previous_answer=previous_answer,\n",
    "    video_metadata=video_metadata\n",
    ")\n",
    "\n",
    "print(f\"Follow up analysis: {followup_questions.follow_up_analysis}\")\n",
    "for q in followup_questions.questions:\n",
    "    print(f\"Id: {q.id}, Type: {q.type}\")\n",
    "    print(f\"Text: {q.text}\")\n",
    "    print(f\"Reason: {q.reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_answer = print_result(\n",
    "    file_uri=file_uri, \n",
    "    question=\"How did Connie calculate the duration when the playback rate was randomized?\",\n",
    "    video_metadata=video_metadata\n",
    ")\n",
    "\n",
    "followup_questions = get_followup_questions(\n",
    "    file_uri=file_uri, \n",
    "    previous_answer=previous_answer,\n",
    "    video_metadata=video_metadata\n",
    ")\n",
    "\n",
    "print(f\"Follow up analysis: {followup_questions.follow_up_analysis}\")\n",
    "for q in followup_questions.questions:\n",
    "    print(f\"Id: {q.id}, Type: {q.type}\")\n",
    "    print(f\"Text: {q.text}\")\n",
    "    print(f\"Reason: {q.reason}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
