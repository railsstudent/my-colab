{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ffdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b25708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"<Gemini API Key>\"\n",
    "# api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"GOOGLE_API_KEY not found in .env file\") \n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the File Search store with an optional display name\n",
    "file_search_store = client.file_search_stores.create(config={'display_name': 'generative_ai_leader'})\n",
    "print(file_search_store.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_file_search_store(file_search_store_name: str, file: str, display_name: str):\n",
    "    # Upload to file search store with custom chunking config\n",
    "    operation = client.file_search_stores.upload_to_file_search_store(\n",
    "        file_search_store_name=file_search_store_name,\n",
    "        file=file,\n",
    "        config={\n",
    "            \"display_name\": display_name,\n",
    "            \"chunking_config\": {\n",
    "                \"white_space_config\": {\n",
    "                    \"max_tokens_per_chunk\": 300,\n",
    "                    \"max_overlap_tokens\": 50\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Wait until the upload is complete\n",
    "    while not operation.done:\n",
    "        time.sleep(5)\n",
    "        operation = client.operations.get(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f572ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def get_citations(grounding_metadata: Any):\n",
    "    if grounding_metadata is None:\n",
    "        return []\n",
    "    \n",
    "    chunks = grounding_metadata.grounding_chunks\n",
    "    supports = grounding_metadata.grounding_supports\n",
    "\n",
    "    has_grounding = chunks is not None and supports is not None\n",
    "    print (has_grounding)\n",
    "    if has_grounding is False:\n",
    "        return []\n",
    "\n",
    "    citations = []\n",
    "    for support in supports:\n",
    "        indices = support.grounding_chunk_indices\n",
    "        for index in indices:\n",
    "            source = chunks[index].retrieved_context\n",
    "            source_title = source.title\n",
    "            citation = support.segment.text\n",
    "            start_index = support.segment.start_index\n",
    "            end_index = support.segment.end_index\n",
    "\n",
    "            citation = {\n",
    "                \"title\": source_title,\n",
    "                \"text\": f\"[{start_index}-{end_index}] {citation}\"\n",
    "            }\n",
    "            citations.append(citation)\n",
    "\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1bb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question: str):    \n",
    "    # Ask a question about the file\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=question,\n",
    "        config=types.GenerateContentConfig(tools=[\n",
    "            types.Tool(file_search=types.FileSearch(\n",
    "                file_search_store_names=[file_search_store.name],\n",
    "                top_k=1\n",
    "            ))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    citations = get_citations(response.candidates[0].grounding_metadata) if response is not None and response.candidates is not None and len(response.candidates) > 0 and response.candidates[0].grounding_metadata is not None else []\n",
    "\n",
    "    return {\n",
    "        \"answer\": response.text,\n",
    "        \"citations\": citations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a34136",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_to_file_search_store(\n",
    "    file_search_store_name=file_search_store.name, \n",
    "    file=\"generative_ai_leader_study_guide_english.pdf\", \n",
    "    display_name=\"genai_leader_study_guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_to_file_search_store(\n",
    "    file_search_store_name=file_search_store.name, \n",
    "    file=\"generative_ai_leader_exam_guide_english.pdf\", \n",
    "    display_name=\"genai_leader_exam_guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_answer(question=\"\"\"How to make a successful Generative AI solution?\"\"\")\n",
    "\n",
    "print(\"Answer\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for citation in (response[\"citations\"] or []):\n",
    "    print(f\"Source: {citation[\"title\"]}, text: {citation[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_answer(question=\"\"\"What will be tested in section 3 of the exam guide? Please output in Markdown format\"\"\")\n",
    "\n",
    "print(\"Answer\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610af91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for citation in (response[\"citations\"] or []):\n",
    "    print(f\"Source: {citation[\"title\"]}, text: {citation[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef814eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_answer(question=\"\"\"What is the capital of China?\"\"\")\n",
    "\n",
    "print(\"Answer\", response[\"answer\"])\n",
    "for citation in (response[\"citations\"] or []):\n",
    "    print(f\"Source: {citation[\"title\"]}, text: {citation[\"text\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the file search store is deleted permanently\n",
    "all_stores = client.file_search_stores.list()\n",
    "for store in all_stores:\n",
    "        # Delete a file search store\n",
    "        client.file_search_stores.delete(name=store.name, config={ \"force\": True })\n",
    "        print(store.name, \" is deleted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
