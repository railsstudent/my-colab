{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install matplotlib\n",
    "%pip install os\n",
    "%pip install dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown\n",
    "from urllib.error import URLError\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GendersVerification(BaseModel):\n",
    "    result: bool = Field(description=\"Whether the genders are opposite.\")\n",
    "    stop_reason: str | None = Field(None, description=\"The stop reason when result is False.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vertexai_client():\n",
    "    import os\n",
    "    \n",
    "    cloud_api_key = os.getenv(\"GOOGLE_CLOUD_API_KEY\")\n",
    "    if not cloud_api_key:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_API_KEY not found in .env file\")\n",
    "    \n",
    "    # Configure the client with your API key\n",
    "    client = genai.Client(\n",
    "        vertexai=True, \n",
    "        api_key=cloud_api_key, \n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url: str):\n",
    "    try:\n",
    "        response = requests.get(url=url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except requests.HTTPError as e:\n",
    "        # e.code contains the status code (e.g., 404)\n",
    "        if e.code == 404:\n",
    "            print(\"Error: URL not found (404).\")\n",
    "        else:\n",
    "            print(f\"HTTP Error: {e.code}\")\n",
    "       \n",
    "    except URLError:\n",
    "        print(f\"Error: The file at '{url}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_usage(response: types.GenerateContentResponse):\n",
    "    if response and response.usage_metadata:\n",
    "        usage_metadata = response.usage_metadata\n",
    "        input_token_count = usage_metadata.prompt_token_count\n",
    "        output_token_count = usage_metadata.candidates_token_count\n",
    "        total_token_count = usage_metadata.total_token_count\n",
    "        thought_token_count = usage_metadata.thoughts_token_count\n",
    "        cached_token_count = usage_metadata.cached_content_token_count\n",
    "        print(f\"Input: {input_token_count}, Output: {output_token_count}, Thought: {thought_token_count}, Cached: {cached_token_count} Total: {total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f44d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Configure the client with your API key\n",
    "client = create_vertexai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_genders(person_a_image_url: str, person_b_image_url: str):\n",
    "    def clean_json_string(raw_string):\n",
    "        # Remove the markdown code blocks\n",
    "        clean_str = raw_string.strip()\n",
    "        if clean_str.startswith(\"```json\"):\n",
    "            clean_str = clean_str[7:]\n",
    "        if clean_str.endswith(\"```\"):\n",
    "            clean_str = clean_str[:-3]\n",
    "        return clean_str.strip()\n",
    "    \n",
    "    gender_verification_prompt = \"\"\"\n",
    "    Role: You are an Advanced Image Content Validator. Your goal is to identify human subjects for a biological analysis tool, even in complex images.\n",
    "\n",
    "    Task: Analyze two input images (Image A and Image B). Locate the primary human subject in each image and verify their genders.\n",
    "\n",
    "    Validation & Selection Logic:\n",
    "\n",
    "    1. Smart Subject Detection:\n",
    "    - Scan each image for a human face or figure.\n",
    "    - Crucial: If an image contains both humans and objects (e.g., a person holding a guitar, a person next to a car, or a person in a cluttered room), you must ignore the objects and focus exclusively on the human.\n",
    "    - If multiple humans are present, select the most prominent/clearest face as the subject for that image.\n",
    "    - Failure Condition: If no recognizable human face is found in one or both images (e.g., only a landscape, animal, or object is visible), set \"result\" to false and \"stop_reason\" to \"One or both images do not contain a detectable human face.\"\n",
    "\n",
    "    2. Gender Verification:\n",
    "    - Analyze the biological sex or gender presentation of the selected human subject in Image A and Image B.\n",
    "    - Failure Condition: If the subjects are of the same gender (Male+Male or Female+Female), set \"result\" to false and \"stop_reason\" to \"Please upload one male and one female.\"\n",
    "\n",
    "    3. Pass Condition:\n",
    "    - If both images contain a human subject AND they are of opposite genders (One Male + One Female), set \"result\" to true and \"stop_reason\" to null.\n",
    "\n",
    "    Output Schema:\n",
    "    Return ONLY a single JSON object with no markdown formatting or additional text.\n",
    "\n",
    "    {\n",
    "    \"result\": boolean,\n",
    "    \"stop_reason\": string | null\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=gender_verification_prompt),\n",
    "                    types.Part.from_uri(file_uri=person_a_image_url),\n",
    "                    types.Part.from_uri(file_uri=person_b_image_url),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=GendersVerification.model_json_schema(),\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_HIGH,\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=types.ThinkingLevel.HIGH\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "\n",
    "    result = GendersVerification.model_validate_json(clean_json_string(response.text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9341c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sibling_images(person_a_image_url: str, person_b_image_url: str):\n",
    "    prompt = \"\"\"\n",
    "    A group portrait of four distinct young adult siblings (two males, two females, aged 18-22). \n",
    "    They are the biological offspring of the provided references, generated with **high genetic variability**. \n",
    "    The faces must display a **randomized distribution of traits**, where features (eyes, nose, mouth, jawline) are mixed **unequally** across the four subjects. \n",
    "    Ensure distinctiveness: Sibling 1 should lean strongly towards the father's features, Sibling 2 towards the mother's, while Siblings 3 and 4 represent complex, unique mixes of recessive and dominant traits. \n",
    "    **Crucial:** All four must have fresh, smooth, youthful skin and collegiate appearances. \n",
    "    Do not transfer the parents' wrinkles or skin texture. 2k resolution, photorealistic, detailed distinct faces.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-pro-image-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=prompt),\n",
    "                    types.Part.from_uri(file_uri=person_a_image_url),\n",
    "                    types.Part.from_uri(file_uri=person_b_image_url),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=['TEXT', 'IMAGE'],\n",
    "            image_config=types.ImageConfig(\n",
    "                image_size=\"2K\",  \n",
    "                aspect_ratio=\"3:2\"\n",
    "            ),\n",
    "            temperature=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "\n",
    "    image_bytes: bytes | None = None\n",
    "    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.thought and part.text:\n",
    "                display(Markdown(f\"Though Summary:\\n {part.text}\"))\n",
    "            elif part.text:\n",
    "                print(\"Text: \", part.text)\n",
    "            if part.inline_data:\n",
    "                image_bytes = part.inline_data.data\n",
    "       \n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b56c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(person_a_image: str, person_b_image: str):\n",
    "    base_url = \"https://raw.githubusercontent.com/railsstudent/colab_images/refs/heads/main/couples\"\n",
    "    person_a_image_url = f\"{base_url}/{person_a_image}\"\n",
    "    person_b_image_url = f\"{base_url}/{person_b_image}\"\n",
    "\n",
    "    load_image_from_url(url=person_a_image_url)\n",
    "    load_image_from_url(url=person_b_image_url)\n",
    "\n",
    "    result = verify_genders(person_a_image_url=person_a_image_url, person_b_image_url=person_b_image_url)\n",
    "    if result.result:\n",
    "        offspring_bytes = generate_sibling_images(\n",
    "            person_a_image_url=person_a_image_url, \n",
    "            person_b_image_url=person_b_image_url\n",
    "        )\n",
    "        offspring_image = Image.open(BytesIO(offspring_bytes)) if offspring_bytes else None\n",
    "        if offspring_image:\n",
    "            plt.imshow(offspring_image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        pass\n",
    "    else:\n",
    "        if result.stop_reason:\n",
    "            print (\"Stop reason:\", result.stop_reason)\n",
    "\n",
    "def print_test_cases(heading: str, cases: list[list[str]]):\n",
    "    print(heading)\n",
    "    for case in cases:\n",
    "        print_result(person_a_image=case[0], person_b_image=case[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_test_cases(heading=\"Couple cases\", cases=[\n",
    "#     [\"victoria_beckham.jpg\", \"david_beckham.webp\"]\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_cases(heading=\"Couple cases\", cases=[\n",
    "    [\"poi.jpg\", \"shingo-takagi.png\"],\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
