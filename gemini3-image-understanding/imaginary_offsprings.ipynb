{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install matplotlib\n",
    "%pip install os\n",
    "%pip install dotenv\n",
    "%pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown\n",
    "from urllib.error import URLError\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GendersVerification(BaseModel):\n",
    "    result: bool = Field(description=\"Whether the genders are opposite.\")\n",
    "    stop_reason: str | None = Field(None, description=\"The stop reason when result is False.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vertexai_client():\n",
    "    import os\n",
    "    \n",
    "    cloud_api_key = os.getenv(\"GOOGLE_CLOUD_API_KEY\")\n",
    "    if not cloud_api_key:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_API_KEY not found in .env file\")\n",
    "    \n",
    "    # Configure the client with your API key\n",
    "    client = genai.Client(\n",
    "        vertexai=True, \n",
    "        api_key=cloud_api_key, \n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689890f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url: str):\n",
    "    try:\n",
    "        response = requests.get(url=url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except requests.HTTPError as e:\n",
    "        # e.code contains the status code (e.g., 404)\n",
    "        if e.code == 404:\n",
    "            print(\"Error: URL not found (404).\")\n",
    "        else:\n",
    "            print(f\"HTTP Error: {e.code}\")\n",
    "       \n",
    "    except URLError:\n",
    "        print(f\"Error: The file at '{url}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_usage(response: types.GenerateContentResponse):\n",
    "    if response and response.usage_metadata:\n",
    "        usage_metadata = response.usage_metadata\n",
    "        input_token_count = usage_metadata.prompt_token_count\n",
    "        output_token_count = usage_metadata.candidates_token_count\n",
    "        total_token_count = usage_metadata.total_token_count\n",
    "        thought_token_count = usage_metadata.thoughts_token_count\n",
    "        cached_token_count = usage_metadata.cached_content_token_count\n",
    "        print(f\"Input: {input_token_count}, Output: {output_token_count}, Thought: {thought_token_count}, Cached: {cached_token_count} Total: {total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f44d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Configure the client with your API key\n",
    "client = create_vertexai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_string(raw_string):\n",
    "        # Remove the markdown code blocks\n",
    "        clean_str = raw_string.strip()\n",
    "        if clean_str.startswith(\"```json\"):\n",
    "            clean_str = clean_str[7:]\n",
    "        if clean_str.endswith(\"```\"):\n",
    "            clean_str = clean_str[:-3]\n",
    "        return clean_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_genders(person_a_image_url: str, person_b_image_url: str):\n",
    "    gender_verification_prompt = \"\"\"\n",
    "    Role: You are an Advanced Image Content Validator. Your goal is to identify human subjects for a biological analysis tool, even in complex images.\n",
    "\n",
    "    Task: Analyze two input images (Image A and Image B). Locate the primary human subject in each image and verify their genders.\n",
    "\n",
    "    Validation & Selection Logic:\n",
    "\n",
    "    1. Smart Subject Detection:\n",
    "    - Scan each image for a human face or figure.\n",
    "    - Crucial: If an image contains both humans and objects (e.g., a person holding a guitar, a person next to a car, or a person in a cluttered room), you must ignore the objects and focus exclusively on the human.\n",
    "    - If multiple humans are present, select the most prominent/clearest face as the subject for that image.\n",
    "    - Failure Condition: If no recognizable human face is found in one or both images (e.g., only a landscape, animal, or object is visible), set \"result\" to false and \"stop_reason\" to \"One or both images do not contain a detectable human face.\"\n",
    "\n",
    "    2. Gender Verification:\n",
    "    - Analyze the biological sex or gender presentation of the selected human subject in Image A and Image B.\n",
    "    - Failure Condition: If the subjects are of the same gender (Male+Male or Female+Female), set \"result\" to false and \"stop_reason\" to \"Please upload one male and one female.\"\n",
    "\n",
    "    3. Pass Condition:\n",
    "    - If both images contain a human subject AND they are of opposite genders (One Male + One Female), set \"result\" to true and \"stop_reason\" to null.\n",
    "\n",
    "    Output Schema:\n",
    "    Return ONLY a single JSON object with no markdown formatting or additional text.\n",
    "\n",
    "    {\n",
    "    \"result\": boolean,\n",
    "    \"stop_reason\": string | null\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=gender_verification_prompt),\n",
    "                    types.Part.from_uri(file_uri=person_a_image_url),\n",
    "                    types.Part.from_uri(file_uri=person_b_image_url),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=GendersVerification.model_json_schema(),\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_HIGH,\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=types.ThinkingLevel.HIGH\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "\n",
    "    result = GendersVerification.model_validate_json(clean_json_string(response.text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d99ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentifyCouple(BaseModel):\n",
    "    couple: list[str] = Field(...,description=\"The name of the couple. Return unknown when not sure.\")\n",
    "    is_married: bool = Field(..., description=\"True when the couple is married. Otherwise, return false.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_couple(person_a_image_url: str, person_b_image_url: str):\n",
    "    from datetime import date\n",
    "\n",
    "    today = date.today()\n",
    "    formatted_date = today.strftime(\"%b %Y\")\n",
    "\n",
    "    identify_couple_prompt = f\"\"\"\n",
    "        Task: Analyze the two provided images, (Image A and Image B), to identify the public figures shown. \n",
    "\n",
    "        Verification: Once you have identified them, use the Google Search tool to verify their current relationship status as of {formatted_date}. \n",
    "        Specifically, investigate whether they are legally married to each other at this time.\n",
    "        \n",
    "        Constraint: You must return your answer **strictly** as a JSON object following the schema below. \n",
    "        Do not include conversational text or markdown outside of the JSON. \n",
    "        If the individuals are not public figures or cannot be identified, return the names as \"unknown\" and the boolean as `false`.\n",
    "\n",
    "        output_format:\n",
    "        ```json\n",
    "        {{\n",
    "            \"couple\": [ \"<Full Name 1 of Image A>\", \"<Full Name 2 of Image B>\" ],\n",
    "            \"is_married\": <boolean>\n",
    "        }}\n",
    "        ```json\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=identify_couple_prompt),\n",
    "                    types.Part.from_uri(file_uri=person_a_image_url),\n",
    "                    types.Part.from_uri(file_uri=person_b_image_url),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_json_schema=IdentifyCouple.model_json_schema(),\n",
    "            media_resolution=types.MediaResolution.MEDIA_RESOLUTION_HIGH,\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=types.ThinkingLevel.HIGH\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "\n",
    "    result = IdentifyCouple.model_validate_json(clean_json_string(response.text))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9341c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sibling_images(person_a_image_url: str, person_b_image_url: str):\n",
    "    prompt = \"\"\"\n",
    " **Task:** Generate a photorealistic group portrait of four young adult siblings (two males, two females, aged 18-22) standing together. They must look like a cohesive family unit and the **direct biological offspring** of the two provided individuals.\n",
    "\n",
    " **Inheritance Logic (Mandatory):**\n",
    " 1. **Shared Ancestral Phenotype:** The siblings must strictly reflect the **combined ethnic heritage, bone structure, and facial proportions** visible in the parents. If the parents are from different backgrounds, create a consistent mixed-heritage look across the group.\n",
    " 2. **Sibling 1 (Male):** Inherits the **facial geometry and jawline** of Parent 1, but with the **skin tone and hair texture** of Parent 2.\n",
    " 3. **Sibling 2 (Female):** Inherits the **eye shape and nose bridge** of Parent 2, but with the **overall face shape** of Parent 1.\n",
    " 4. **Sibling 3 (Male):** A dominant blend of both parents, displaying **Parent 1's brow line** and **Parent 2's mouth/lip structure**.\n",
    " 5. **Sibling 4 (Female):** A complex mix where recessive traits appear; inherit the **ear shape and eye color** of Parent 1, but the **cheekbone height** of Parent 2.\n",
    "\n",
    " **Consistency & Quality:**\n",
    " * Family Resemblance: Ensure all four siblings share at least one distinct feature (e.g., the specific shape of the nose or the set of the eyes) that is clearly traceable to the parents.\n",
    " * Youthful Polish: All siblings must have fresh, smooth, collegiate skin. **Crucial:** Do not transfer aging markers, wrinkles, or sun-damaged textures from the parent photos. \n",
    " * Environment: A high-quality 2k portrait in a neutral university courtyard, photorealistic lighting, with a shallow depth of field.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-pro-image-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=prompt),\n",
    "                    types.Part.from_uri(file_uri=person_a_image_url),\n",
    "                    types.Part.from_uri(file_uri=person_b_image_url),\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=['TEXT', 'IMAGE'],\n",
    "            image_config=types.ImageConfig(\n",
    "                image_size=\"2K\",  \n",
    "                aspect_ratio=\"3:2\"\n",
    "            ),\n",
    "            temperature=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "\n",
    "    image_bytes: bytes | None = None\n",
    "    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.thought and part.text:\n",
    "                display(Markdown(f\"Though Summary:\\n {part.text}\"))\n",
    "            elif part.text:\n",
    "                print(\"Text: \", part.text)\n",
    "            if part.inline_data:\n",
    "                image_bytes = part.inline_data.data\n",
    "       \n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b56c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(person_a_image: str, person_b_image: str):\n",
    "    base_url = \"https://raw.githubusercontent.com/railsstudent/colab_images/refs/heads/main/couples\"\n",
    "    person_a_image_url = f\"{base_url}/{person_a_image}\"\n",
    "    person_b_image_url = f\"{base_url}/{person_b_image}\"\n",
    "\n",
    "    load_image_from_url(url=person_a_image_url)\n",
    "    load_image_from_url(url=person_b_image_url)\n",
    "\n",
    "    gender_result = verify_genders(person_a_image_url=person_a_image_url, person_b_image_url=person_b_image_url)\n",
    "    couple_result = identify_couple(person_a_image_url=person_a_image_url, person_b_image_url=person_b_image_url)\n",
    "    \n",
    "    print (\"Who are they?\")\n",
    "    print (f\"* {couple_result.couple}. Are they married? {couple_result.is_married}\")\n",
    "    \n",
    "    if gender_result.result:\n",
    "        offspring_bytes = generate_sibling_images(\n",
    "            person_a_image_url=person_a_image_url, \n",
    "            person_b_image_url=person_b_image_url\n",
    "        )\n",
    "        offspring_image = Image.open(BytesIO(offspring_bytes)) if offspring_bytes else None\n",
    "        if offspring_image:\n",
    "            plt.imshow(offspring_image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        pass\n",
    "    else:\n",
    "        if gender_result.stop_reason:\n",
    "            print (\"Stop reason:\", gender_result.stop_reason)\n",
    "\n",
    "def print_test_cases(heading: str, cases: list[list[str]]):\n",
    "    print(heading)\n",
    "    for case in cases:\n",
    "        print_result(person_a_image=case[0], person_b_image=case[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_cases(heading=\"Couple cases\", cases=[\n",
    "    [\"victoria_beckham.jpg\", \"david_beckham.webp\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_cases(heading=\"Couple cases\", cases=[\n",
    "    [\"poi.jpg\", \"shingo-takagi.png\"],\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
