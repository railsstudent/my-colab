{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b86abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install matplotlib\n",
    "%pip install os\n",
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genai_client():\n",
    "    import os\n",
    "\n",
    "    # api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    # if not api_key:\n",
    "    #     raise ValueError(\"GOOGLE_API_KEY not found in .env file\")\n",
    "    \n",
    "    cloud_api_key = os.getenv(\"GOOGLE_CLOUD_API_KEY\")\n",
    "    if not cloud_api_key:\n",
    "        raise ValueError(\"GOOGLE_CLOUD_API_KEY not found in .env file\")\n",
    "    \n",
    "    # Configure the client with your API key\n",
    "    # client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})\n",
    "    client = genai.Client(\n",
    "        vertexai=True, \n",
    "        api_key=cloud_api_key, \n",
    "        # http_options={'api_version': 'v1alpha'}\n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73765af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Configure the client with your API key\n",
    "client = create_genai_client()\n",
    "\n",
    "tools = [types.Tool(google_search=types.GoogleSearch())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path: str):\n",
    "    try:\n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{image_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "def print_token_usage(response: types.GenerateContentResponse):\n",
    "    if response and response.usage_metadata:\n",
    "        usage_metadata = response.usage_metadata\n",
    "        input_token_count = usage_metadata.prompt_token_count\n",
    "        output_token_count = usage_metadata.candidates_token_count\n",
    "        total_token_count = usage_metadata.total_token_count\n",
    "        thought_token_count = usage_metadata.thoughts_token_count\n",
    "        cached_token_count = usage_metadata.cached_content_token_count\n",
    "        print(f\"Input: {input_token_count}, Output: {output_token_count}, Thought: {thought_token_count}, Cached: {cached_token_count} Total: {total_token_count}\")\n",
    "        \n",
    "def get_num_citations(grounding_supports: list[types.GroundingSupport] | None):\n",
    "    num_citations = 0\n",
    "    for support in grounding_supports or []:\n",
    "        if support.grounding_chunk_indices:\n",
    "            num_citations = num_citations + len(support.grounding_chunk_indices)\n",
    "\n",
    "    return num_citations\n",
    "\n",
    "def build_citations(grounding_supports: list[types.GroundingSupport] | None, grounding_chunks: list[types.GroundingChunk] | None):\n",
    "    citations: list[str] = []\n",
    "    for support in grounding_supports:\n",
    "        if support.grounding_chunk_indices:\n",
    "            for i in support.grounding_chunk_indices:\n",
    "                uri = ''\n",
    "                if grounding_chunks and i < len(grounding_chunks):\n",
    "                    chunk = grounding_chunks[i]\n",
    "                    uri = chunk.web.uri if chunk.web and chunk.web.uri else ''\n",
    "                if uri:\n",
    "                    citations.append(uri)\n",
    "\n",
    "    text_citations = \"\\nCitation link: \".join(citations)\n",
    "    return \"Citation link: \" + text_citations\n",
    "\n",
    "def execute_prompt(prompt: str):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-pro-preview\",\n",
    "        contents=[types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=prompt)]\n",
    "        )],\n",
    "        config=types.GenerateContentConfig(\n",
    "            tools=tools,\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=types.ThinkingLevel.HIGH\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print_token_usage(response)\n",
    "    return response\n",
    "\n",
    "def print_response(response: types.GenerateContentResponse):\n",
    "    # print the response\n",
    "    display(Markdown(f\"Response:\\n {response.text}\"))\n",
    "\n",
    "    grounding_metadata = response.candidates[0].grounding_metadata if response.candidates and response.candidates[0] and response.candidates[0].grounding_metadata else None\n",
    "    grounding_chunks = grounding_metadata.grounding_chunks if grounding_metadata and grounding_metadata.grounding_chunks else None\n",
    "    grounding_supports = grounding_metadata.grounding_supports if grounding_metadata and grounding_metadata.grounding_supports else None\n",
    "    if grounding_supports and grounding_chunks:\n",
    "        print (f\"{get_num_citations(grounding_supports)} Citations\")\n",
    "        citations = build_citations(grounding_supports=grounding_supports, grounding_chunks=grounding_chunks)\n",
    "        print(citations)\n",
    "\n",
    "    web_search_queries = grounding_metadata.web_search_queries if grounding_metadata and grounding_metadata.web_search_queries else None\n",
    "    if web_search_queries and len(web_search_queries) > 0:\n",
    "        for query in web_search_queries:\n",
    "            if query:\n",
    "                print (f\"Query -> {query}\")\n",
    "        \n",
    "def generate_weather_forecast():\n",
    "    prompt = \"\"\"\n",
    "    Please search for the latest confirmed weather forecast for Taiwan for the dates listed below in 2025. specifically looking at Taipei and Taoyuan.\n",
    "    The dates and locations are:\n",
    "    1. Taipei: November 26, 27, 28, and 29.\n",
    "    2. Taoyuan: November 30 and December 1.\n",
    "    November has 30 days, so avoid doing weather forecast for November 31.\n",
    "    Then generate a weather forecast image, add appropriate clothing on each day and in Traditional Chinese.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-pro-image-preview\",\n",
    "        contents=[types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=prompt)]\n",
    "        )],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=['TEXT', 'IMAGE'],\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                include_thoughts=True,\n",
    "                thinking_budget=512,\n",
    "            ),\n",
    "            tools=tools,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    image_bytes: bytes | None = None\n",
    "    print_token_usage(response)\n",
    "    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.thought and part.text:\n",
    "                display(Markdown(f\"Thought Summary:\\n {part.text}\"))\n",
    "            elif part.text:\n",
    "                print(\"Text: \", part.text)\n",
    "            elif part.inline_data:\n",
    "                image_bytes = part.inline_data.data\n",
    "       \n",
    "    return image_bytes\n",
    "\n",
    "def generate_trip_poster():\n",
    "    prompt = \"\"\"\n",
    "    A vertical movie-style travel poster titled \"TAIPEI 2025\" in Traditional Chinese. \n",
    "    The composition is a dynamic vertical montage illustrating a journey.\n",
    "    Please use Google Search tool to find out how the landmarks look like and include them in the poster.\n",
    "\n",
    "    Visual Elements (blended from bottom to top):\n",
    "    1. Bottom Section (City & Tech): A bustling street scene featuring \"Tenlong Computer Books\" and stacks of coding books, merging into the bright neon lights of Ximending and the towering Taipei 101 at night.\n",
    "    2. Middle Section (Nature & Relax): Steam rising from a traditional Beitou Hot Spring bath set against the lush green backdrop of Yangmingshan mountains.  Please display Beitou and Yangmingshan in Traditional Chinese. \n",
    "    3. Top Section (Action & Return): A dynamic female pro-wrestling ring scene (Diana Wrestling) acting as the climax, Azure AI Logo over 臺灣大學社會科學院, with a stylized airplane flying overhead towards a silhouette of the Hong Kong skyline in the clouds.\n",
    "    4. The female wreslers must look Japanese or Taiwanese.\n",
    "    \n",
    "    Style: Vibrant semi-realistic digital art, high saturation, distinct color zones for each location, 8k resolution, cinematic lighting, highly detailed.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-pro-image-preview\",\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[types.Part(text=prompt)]\n",
    "            )\n",
    "        ],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=['TEXT', 'IMAGE'],\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                include_thoughts=True,\n",
    "                thinking_budget=512,\n",
    "            ),\n",
    "            tools=tools,\n",
    "            image_config=types.ImageConfig(\n",
    "                aspect_ratio=\"9:16\",\n",
    "                image_size=\"4K\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    image_bytes: bytes | None = None\n",
    "    print_token_usage(response)\n",
    "    if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.thought and part.text:\n",
    "                display(Markdown(f\"Though Summary:\\n {part.text}\"))\n",
    "            elif part.text:\n",
    "                print(\"Text: \", part.text)\n",
    "            elif part.inline_data:\n",
    "                image_bytes = part.inline_data.data\n",
    "       \n",
    "    return image_bytes\n",
    "\n",
    "def save_and_show_image(image_bytes: bytes, file_name=\"./image.png\"):\n",
    "    image = Image.open(BytesIO(image_bytes)) if image_bytes else None\n",
    "    if image:\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        image.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b56c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = execute_prompt(prompt=\"\"\"\n",
    "    Please search for the latest confirmed weather forecast for Taiwan for the dates listed below in 2025. specifically looking at Taipei and Taoyuan.\n",
    "    \n",
    "    Present the results in a single clear table with the following columns: Date, Location, Weather (Condition, Temp in °C, Precipitation %), and Appropriate Clothing.\n",
    "\n",
    "    The dates and locations are:\n",
    "    1. Taipei: November 26, 27, 28, and 29.\n",
    "    2. Taoyuan: November 30 and December 1.\n",
    "\"\"\")\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_forecast = response.text\n",
    "response = execute_prompt(prompt=f\"\"\"\n",
    "    Based on the weather forecast you just retrieved and the itinerary details below, please act as a professional travel planner and generate a comprehensive packing list.\n",
    "\n",
    "    Trip Itinerary:\n",
    "    - November 26, 2025 - November 29, 2025: Taipei (City exploration, night markets, extensive walking).\n",
    "    - November 30, 2025 - December 1, 2025: Taoyuan (Transitioning closer to the airport/coastal area).\n",
    "\n",
    "    Please categorize the packing list into:\n",
    "\n",
    "    1. Clothing: Specific recommendations based on the temperature and rain forecast you found. Suggest layers suitable for transitioning between humid outdoor weather, likely rain, and strong indoor air conditioning. Recommend shoes suitable for wet pavement and high daily step counts.\n",
    "    2. Documents: Entry requirements for Taiwan, digital backups, and essential travel apps.\n",
    "    3. Financial: Advice on carrying cash (TWD) vs. credit cards, specifically distinguishing between Night Market needs vs. Malls/Department stores.\n",
    "    4. Electronics: Adapter types (confirm if US plugs work in Taiwan), power banks, and connectivity (eSIM vs. physical SIM).\n",
    "    5. Essentials: Toiletries, Feminine products and specific items for humid weather. \n",
    "    6. Taoyuan Logistics: Any specific tips for moving between Taipei and Taoyuan (e.g., keeping travel documents accessible).\n",
    "    7. Airport Logistics: Any specific tips for moving between the hotel I am staying in Taoyuan and the airport.\n",
    "\n",
    "    Special Request: Include a \"Taiwan Essentials\" section, including the EasyCard (transport card) and specific umbrella recommendations.\n",
    "    \n",
    "    Weather forecast:\n",
    "    {weather_forecast}\n",
    "    \"\"\")\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = execute_prompt(prompt=\"\"\"\n",
    "    Please search the web for my Cathay Pacific flight on November 26, 2025 from Hong Kong to Taipei. The flight number is CX530.\n",
    "    The departure flight is CX495 on December 1, 2025. \n",
    "      \n",
    "    Present the results in a single clear table with the following columns: Date, From, To, Flight Provider, Flight  Number, Plane Model, Departure, Arrival.\n",
    "    The From column includes location, airport code, and terminal, in the format of  <Location> (<Code>) - <Terminal>\n",
    "    Similarly, the To column includes the the same information in the same format.\"\"\"\n",
    ")\n",
    "\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_bytes = generate_weather_forecast()\n",
    "# save_and_show_image(image_bytes=image_bytes, file_name='./weather_forecast.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_bytes = generate_trip_poster()\n",
    "# save_and_show_image(image_bytes=image_bytes, file_name='./poster.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
